{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eXamine Project\n",
    "\n",
    "\n",
    "\n",
    "1. The Dataset is in a folder named \"Dataset_clean\" with a total of 780 ultrasound images acquired from public databases. These images are further split into train and validation sets, each containing benign, malignant, and normal ultrasound images. These three classes will be the final output of our machine learning model.\n",
    "\n",
    "\n",
    "2. A total of three models have been tested and trained to find the best model with the highest validation accuracy: neural network, transfer learning with Resnet50, and convolutional neural network. Considering runtime, validation accuracy, and validation loss, the best model was found to be a convolutional neural network model trained from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'datax/Dataset_clean/Datasets'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python # install this if you don't have opencv already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(os.path.expanduser('~'), 'datax/Dataset_clean/Datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "DATADIR = path\n",
    "CATEGORIES = [\"benign\", \"malignant\", \"normal\"]\n",
    "\n",
    "for category in CATEGORIES:  \n",
    "    path = os.path.join(DATADIR,category)  \n",
    "    for img in os.listdir(path):  \n",
    "        img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "        plt.imshow(img_array, cmap='gray')  # graph it\n",
    "        plt.show()  # display\n",
    "\n",
    "        break\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resizing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 100\n",
    "\n",
    "new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "plt.imshow(new_array, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:  \n",
    "\n",
    "        path = os.path.join(DATADIR,category)  # create path\n",
    "        class_num = CATEGORIES.index(category)  # get the classification  (0, 1, 2)\n",
    "\n",
    "        for img in os.listdir(path):  # iterate over each image\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "                training_data.append([new_array, class_num])  # add this to our training_data\n",
    "            except Exception as e:  # keeping the output clean...\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_training_data()\n",
    "\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in training_data[:10]:\n",
    "    print(sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features,label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "# print(X[0].reshape(-1, IMG_SIZE, IMG_SIZE, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing X and y in pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SLIDES\n",
    "\n",
    "import pickle #save this data\n",
    "\n",
    "pickle_out = open(\"X.pickle\",\"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\",\"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "from tensorflow.keras.backend import clear_session\n",
    "import matplotlib.gridspec as gridspec\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# SLIDES\n",
    "\n",
    "X_train_sample, y_train_sample = resample(X,y, replace=False,n_samples=1578, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_sample,y_train_sample,test_size=0.2,\n",
    "                                                  stratify=y_train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SLIDES\n",
    "\n",
    "print(\"Shape of the training images array:\", X_train.shape)\n",
    "print(\"Shape of the training labels array:\", y_train.shape)\n",
    "print(\"Shape of the validation images array:\",X_val.shape)\n",
    "print(\"Shape of the validation labels array:\",y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train) / 255\n",
    "X_val   = np.array(X_val) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SLIDES\n",
    "\n",
    "fig = plt.figure(constrained_layout=True,figsize=(15,4.5))\n",
    "spec_arr = gridspec.GridSpec(ncols=10, nrows=3, figure=fig)\n",
    "for ximg, ylabel, spec in zip(X_train,y_train,spec_arr):\n",
    "  ax = fig.add_subplot(spec)\n",
    "  ax.imshow(ximg)\n",
    "  ax.set_title(\"({0})\".format(ylabel))\n",
    "  ax.set_xticks([])\n",
    "  ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create our neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SLIDES\n",
    "\n",
    "clear_session()\n",
    "initializer_G = keras.initializers.GlorotNormal(seed=0)\n",
    "\n",
    "model_basic = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[100,100]),\n",
    "    keras.layers.Dense(units=100,activation=\"sigmoid\",kernel_initializer=initializer_G),\n",
    "    keras.layers.Dense(units=3,activation=\"softmax\",kernel_initializer=initializer_G)])\n",
    "\n",
    "# model_basic.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "#               optimizer=keras.optimizers.SGD(learning_rate=1),\n",
    "#               metrics=[\"accuracy\"])\n",
    "\n",
    "model_basic.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=0.005),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "print(model_basic.summary())\n",
    "\n",
    "history = model_basic.fit(X_train,y_train,validation_data=(X_val,y_val),batch_size=10,epochs=50,shuffle=False,verbose=1)\n",
    "lr_num = keras.backend.eval(history.model.optimizer.learning_rate)\n",
    "fig, AX = plt.subplots(nrows=1,ncols=2,figsize=(9,4))\n",
    "# plot_learning(history_basic,'lr=1.0','C0',AX[0],AX[1])\n",
    "plot_learning(history,'lr={0}'.format(lr_num),'C1',AX[0],AX[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from keras.applications import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout,Activation,Flatten\n",
    "from keras.applications.resnet import preprocess_input\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/home/jovyan/datax/Datasets/Datasets_CNN/Training/benign/benign (51).png'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "print (x.shape)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "print (x.shape)\n",
    "x = preprocess_input(x)\n",
    "print('Input image shape:', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the training data\n",
    "DATADIR = \"Datasets\"\n",
    "CATEGORIES = [\"benign\", \"malignant\", \"normal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/home/jovyan/datax/Datasets/Datasets_CNN'\n",
    "# Define data path\n",
    "\n",
    "data_dir_list = os.listdir(PATH)\n",
    "data_dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data_list=[]\n",
    "\n",
    "for dataset in data_dir_list:\n",
    "\timg_list=os.listdir(PATH+'/'+ dataset) \n",
    "\tfor img in img_list:\n",
    "\t\timg_path = PATH + '/'+ dataset + '/'+ img \n",
    "\t\timg = image.load_img(img_path, target_size=(224, 224))\n",
    "\t\t#a = img.rotate(90)\n",
    "\t\t#b = img.rotate(180)\n",
    "\t\t#c = img.rotate(270)\n",
    "\t\tx = image.img_to_array(img)\n",
    "\t\t#a1 = image.img_to_array(a)\n",
    "\t\t#b1 = image.img_to_array(b)\n",
    "\t\t#c1 = image.img_to_array(c)\n",
    "\t\tx = np.expand_dims(x, axis=0)\n",
    "\t\t#a1 = np.expand_dims(a1, axis=0)\n",
    "\t\t#b1 = np.expand_dims(b1, axis=0)\n",
    "\t\t#c1 = np.expand_dims(c1, axis=0)\n",
    "\t\tx = preprocess_input(x)\n",
    "\t\t#a1 = preprocess_input(a1)\n",
    "\t\t#b1 = preprocess_input(b1)\n",
    "\t\t#c1 = preprocess_input(c1)\n",
    "\t\t#print('Input image shape:', x.shape)\n",
    "\t\t#print('Input image shape:', a1.shape)\n",
    "\t\t#print('Input image shape:', b1.shape)\n",
    "\t\t#print('Input image shape:', c1.shape)\n",
    "\t\timg_data_list.append(x)\n",
    "\t\t#img_data_list.append(a1)\n",
    "\t\t#img_data_list.append(b1)\n",
    "\t\t#img_data_list.append(c1)\n",
    "\n",
    "img_data = np.array(img_data_list)\n",
    "img_data = img_data.astype('float32')\n",
    "print (img_data.shape)\n",
    "img_data=np.rollaxis(img_data,1,0)\n",
    "print (img_data.shape)\n",
    "img_data=img_data[0]\n",
    "print (img_data.shape)\n",
    "print(len(img_data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of classes\n",
    "num_classes = 3\n",
    "num_of_samples = img_data.shape[0]\n",
    "labels = np.ones((num_of_samples,),dtype='int64')\n",
    "\n",
    "labels[0:260]=0\n",
    "labels[260:520]=1\n",
    "labels[520:]=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"benign\", \"malignant\", \"normal\"]\n",
    "# convert class labels to on-hot encoding\n",
    "Y = np_utils.to_categorical(labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle the dataset\n",
    "x,y = shuffle(img_data,Y, random_state=2)\n",
    "# Split the dataset\n",
    "X_train, X_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input = Input(shape=(224, 224, 3))\n",
    "model = ResNet50(weights='imagenet',include_top=False)\n",
    "model.summary()\n",
    "last_layer = model.output\n",
    "# add a global spatial average pooling layer\n",
    "x = GlobalAveragePooling2D()(last_layer)\n",
    "# add fully-connected & dropout layers\n",
    "x = Dense(512, activation='relu',name='fc-1')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu',name='fc-2')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "# a softmax layer for 4 classes\n",
    "out = Dense(num_classes, activation='softmax',name='output_layer')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "custom_resnet_model2 = Model(inputs=model.input, outputs=out)\n",
    "\n",
    "custom_resnet_model2.summary()\n",
    "\n",
    "for layer in custom_resnet_model2.layers[:-6]:\n",
    "\tlayer.trainable = False\n",
    "\n",
    "custom_resnet_model2.layers[-1].trainable\n",
    "\n",
    "custom_resnet_model2.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "t=time.time()\n",
    "hist = custom_resnet_model2.fit(X_train, y_train, batch_size=32, epochs=3, verbose=1, validation_data=(X_val, y_val))\n",
    "print('Training time: %s' % (t - time.time()))\n",
    "(loss, accuracy) = custom_resnet_model2.evaluate(X_val, y_val, batch_size=10, verbose=1)\n",
    "\n",
    "print(\"[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Mendeley Database'\n",
    "# Define data path\n",
    "\n",
    "new_data_dir_list = os.listdir(path)\n",
    "new_data_dir_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/jovyan/datax/Datasets/Datasets_CNN'\n",
    "train_dir = os.path.join(base_dir, 'Training')\n",
    "validation_dir = os.path.join(base_dir, 'Validation')\n",
    "\n",
    "train_b_dir = os.path.join(train_dir, 'benign')\n",
    "train_m_dir = os.path.join(train_dir, 'malignant')\n",
    "train_n_dir = os.path.join(train_dir, 'normal')\n",
    "\n",
    "validation_b_dir = os.path.join(validation_dir, 'benign')\n",
    "validation_m_dir = os.path.join(validation_dir, 'malignant')\n",
    "validation_n_dir = os.path.join(validation_dir, 'normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_b_fnames = os.listdir(train_b_dir)\n",
    "#print(train_b_fnames[:10])\n",
    "\n",
    "train_m_fnames = os.listdir(train_m_dir)\n",
    "#print(train_m_fnames[:10])\n",
    "\n",
    "train_n_fnames = os.listdir(train_n_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('total training benign images:', len(os.listdir(train_b_dir)))\n",
    "print('total training malignant images:', len(os.listdir(train_m_dir)))\n",
    "print('total training normal images:', len(os.listdir(train_n_dir)))\n",
    "print('total validation benign images:', len(os.listdir(validation_b_dir)))\n",
    "print('total validation malignant images:', len(os.listdir(validation_m_dir)))\n",
    "print('total validation normal images:', len(os.listdir(validation_n_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.1,\n",
    "      height_shift_range=0.1,\n",
    "      shear_range=0.1,\n",
    "      zoom_range=0.1,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "\n",
    "img_path = os.path.join(train_b_dir, train_b_fnames[2])\n",
    "img = load_img(img_path, target_size=(150, 150))  # this is a PIL image\n",
    "x = img_to_array(img)  # Numpy array with shape (150, 150, 3)\n",
    "x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 150, 150, 3)\n",
    "\n",
    "# The .flow() command below generates batches of randomly transformed images\n",
    "i = 0\n",
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,15))\n",
    "for a in range(3):\n",
    "  for batch in datagen.flow(x, batch_size=1):\n",
    "    image = array_to_img(batch[0])\n",
    "    ax[a].imshow(image)\n",
    "    ax[a].axis('off')\n",
    "    #plt.figure(i)\n",
    "    #imgplot = plt.imshow(img)\n",
    "    i += 1\n",
    "    if i % 5 == 0:\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    brightness_range=[0.2,1.0],\n",
    "    horizontal_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,target_size=(150, 150), \n",
    "                                                    batch_size=20, class_mode='categorical')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(validation_dir, target_size=(150, 150), \n",
    "                                                       batch_size=20, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import add\n",
    "from keras.utils import plot_model\n",
    " \n",
    "# function for creating an identity or projection residual module\n",
    "def residual_module(layer_in, n_filters):\n",
    "\tmerge_input = layer_in\n",
    "\t# check if the number of filters needs to be increase, assumes channels last format\n",
    "\tif layer_in.shape[-1] != n_filters:\n",
    "\t\tmerge_input = Conv2D(n_filters, (1,1), padding='same', activation='relu', kernel_initializer='he_normal')(layer_in)\n",
    "\t# conv1\n",
    "\tconv1 = Conv2D(n_filters, (3,3), padding='same', activation='relu', kernel_initializer='he_normal')(layer_in)\n",
    "\t# conv2\n",
    "\tconv2 = Conv2D(n_filters, (3,3), padding='same', activation='linear', kernel_initializer='he_normal')(conv1)\n",
    "\t# add filters, assumes filters/channels last\n",
    "\tlayer_out = add([conv2, merge_input])\n",
    "\t# activation function\n",
    "\tlayer_out = Activation('relu')(layer_out)\n",
    "\treturn layer_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input = layers.Input(shape=(150, 150, 3))\n",
    "\n",
    "x = layers.Conv2D(16, 3, activation='relu')(img_input)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "x = layers.Convolution2D(64, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "#x = residual_module(x, 64)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(1000, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "output = layers.Dense(3, activation='softmax')(x)\n",
    "\n",
    "model = Model(img_input, output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.001), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, \n",
    "                    steps_per_epoch=int(701/20), epochs=20, validation_data=validation_generator, \n",
    "                    validation_steps=int(78/20), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, label = 'training')\n",
    "plt.plot(epochs, val_acc, label = 'validation')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, label = 'training')\n",
    "plt.plot(epochs, val_loss, label = 'validation')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(validation_generator)\n",
    "y_test = validation_generator.classes\n",
    "y_test = label_binarize(y_test, classes=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "n_classes = 3\n",
    "# Plot linewidth.\n",
    "lw = 2\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_pred.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Compute macro-average ROC curve and ROC area\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(1)\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for 3 classes of abnormalities')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction Using ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Dataset_clean/train/normal/normal (13).png'\n",
    "img_test = load_img(path, target_size=(150, 150))\n",
    "print(img_test)\n",
    "img_test = img_to_array(img_test)\n",
    "img_test = img_test.reshape((1,) + img_test.shape)\n",
    "img_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'Mendeley Database'\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(test_dir,target_size=(150, 150), batch_size=20, class_mode='categorical')\n",
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'model_weights_430.pickle'\n",
    "outfile = open(filename,'wb')\n",
    "\n",
    "pickle.dump(w_old,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open(filename,'rb')\n",
    "w_old_unpickled = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "len(w_old_unpickled) #weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_old_unpickled[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_old[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should show the confidence of the model on each diagnosis (my terminology might be off)\n",
    "\n",
    "\n",
    "\n",
    "pred1 = model1.predict(img_test)[0]\n",
    "tot = sum(pred1)\n",
    "print([i/tot for i in pred1])\n",
    "\n",
    "# print(pred1)\n",
    "\n",
    "print(model.predict(img_test)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.layers[10].activation\n",
    "model.layers[10].activation\n",
    "\n",
    "pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import Button, HTML, HBox, VBox, Checkbox, FileUpload, Label, Output, IntSlider, Layout, Image, link\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
